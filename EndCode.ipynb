{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ss8qQMI7CDzu",
    "outputId": "4c9a6e1b-e491-4f8a-99b2-b18b77718605"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PS8wKBCDPsVb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArthurMethodCode.ipynb\n",
      "CascadeTwoPhase.PNG\n",
      "DifferentError.PNG\n",
      "Error.PNG\n",
      "FinalCode.ipynb\n",
      "FinalCode_Avni_Local1.ipynb\n",
      "Loss.PNG\n",
      "Progress.PNG\n",
      "ResizedAndLessPatches.ipynb\n",
      "Segmentation_data.zip\n",
      "Test_seg.zip\n",
      "ThePromisedLand.ipynb\n",
      "final_presentation_example.mov\n",
      "fuck.png\n",
      "slice_126_4.jpg\n",
      "slice_126_GT.jpg\n",
      "trial_0001_input_cascasde_acc.h5\n",
      "trial_MFCcascade_acc.h5\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zElXUf3LCQal"
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgKwRmWGCUGe",
    "outputId": "ea22691a-39b3-4914-ed10-fef331d24dcd"
   },
   "outputs": [],
   "source": [
    "data_path = r'D:\\Grad School Course Work\\CS 6501 - MLIA\\Test_seg' #Change this to wherever the Data Folder is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_2D_y_3D(img): #OHEs the labels for the entire image efficiently\n",
    "    layer1 = 1*(img == 1)\n",
    "    layer2 = 1*(img == 2)\n",
    "    layer3 = 1*(img == 3)\n",
    "    layer4 = 1*(img == 4)\n",
    "    return np.dstack([layer1, layer2, layer3, layer4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_4Knj5tDcqp"
   },
   "source": [
    "Data Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e_lf8FfWH6rp"
   },
   "outputs": [],
   "source": [
    "def model_gen(input_dim,x,y,slice_no):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    Y = []\n",
    "    print(x.shape)\n",
    "    for i in range(int((input_dim)/2),x.shape[0]-int((input_dim)/2), input_dim%3):\n",
    "        for j in range(int((input_dim)/2),x.shape[1]-int((input_dim)/2), input_dim%3):\n",
    "          #Filtering all 0 patches\n",
    "          if(np.count_nonzero(x[i-16:i+17,j-16:j+17,:]) > 100 or x[i,j] != 0): #Check if theres a meaningufl amount of data in the patch\n",
    "#             print(\"({0},{1})\".format(i,j))\n",
    "            X2.append(x[i-16:i+17,j-16:j+17,:])\n",
    "            X1.append(x[i-int((input_dim)/2):i+int((input_dim)/2)+1,j-int((input_dim)/2):j+int((input_dim)/2)+1,:])\n",
    "#             print(\"y_i_j = \", y[i,slice_no,j])\n",
    "            Y.append(y[slice_no,i,j]) #Was i, slice_no, j\n",
    "      \n",
    "      \n",
    "    X1 = np.asarray(X1)\n",
    "    X1 = X1[:,:,:,0]\n",
    "    X2 = np.asarray(X2)\n",
    "    X2 = X2[:,:,:,0]\n",
    "    Y = np.asarray(Y)\n",
    "#     print(\"Pre-y shape\", Y.shape)\n",
    "    to_append_Y = 1*(np.sum(Y, axis=1) > 0) #Add the label for nothing wrong by checking if the other labels aren't zero and append\n",
    "#     print(\"To_append y shape\", to_append_Y.shape)\n",
    "    to_append_Y = to_append_Y.reshape(to_append_Y.shape[0],1)\n",
    "#     print(\"To_append y shape\", to_append_Y.shape)\n",
    "    Y = np.hstack((Y, to_append_Y))\n",
    "#     print(\"X1:\", X1.shape)\n",
    "#     print(\"X1[0]:\", X1[0].shape)\n",
    "#     print(\"X2:\", X2.shape)\n",
    "#     print(\"Y:\",Y.shape)\n",
    "#     print(\"Y[0]:\",Y[0].shape)\n",
    "    d = [X1,X2,Y]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UWtPN8gyImhA"
   },
   "outputs": [],
   "source": [
    "def data_gen(data,y,slice_no,model_no):\n",
    "    d = []\n",
    "    x = data[slice_no]\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "      #filtering all 0 slices and non-tumor slices\n",
    "    if(x.any() != 0 and y.any() != 0):\n",
    "        if(model_no == 0):\n",
    "            X1 = []\n",
    "            for i in range(16,224):##Will need to change to be 240 I believe for out images since this creates the image slices\n",
    "                for j in range(16,224):\n",
    "                    if(np.sum(x[i-16:i+17,j-16:j+17,:]) != 0): #Checks to makes sure data all nonzero\n",
    "                        X1.append(x[i-16:i+17,j-16:j+17,:])\n",
    "            Y1 = []\n",
    "            for i in range(16,224):\n",
    "                for j in range(16,224):\n",
    "                    if(np.sum(x[i-16:i+17,j-16:j+17,:]) != 0):\n",
    "                        Y1.append(y[slice_no,i,j]) \n",
    "            X1 = np.asarray(X1)\n",
    "            X1 = X1[:,:,:,0]\n",
    "            Y1 = np.asarray(Y1)\n",
    "            d = [X1,Y1]\n",
    "        elif(model_no == 1):\n",
    "            d = model_gen(65,x,y,slice_no)\n",
    "        elif(model_no == 2):\n",
    "            d = model_gen(56,x,y,slice_no)\n",
    "        elif(model_no == 3):\n",
    "            d = model_gen(53,x,y,slice_no)  \n",
    "        print(\"Returned\")\n",
    "    return d   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2hFDjvtIqnZ"
   },
   "source": [
    "Model Definations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9RoFhcIyIovB"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Lambda,Concatenate\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Add\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.initializers import glorot_normal\n",
    "#import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dnfO8pP3IxRZ"
   },
   "outputs": [],
   "source": [
    "def two_path(X_input):\n",
    "    # Local path Conv1\n",
    "    X = Conv2D(64,(7,7),strides=(1,1),padding='valid')(X_input)\n",
    "    # Batch-norm\n",
    "    X = BatchNormalization()(X)\n",
    "    X1 = Conv2D(64,(7,7),strides=(1,1),padding='valid')(X_input)\n",
    "    X1 = BatchNormalization()(X1)\n",
    "    # Max-out\n",
    "    X = layers.Maximum()([X,X1])\n",
    "    X = Conv2D(64,(4,4),strides=(1,1),padding='valid',activation='relu')(X)\n",
    "  \n",
    "    # Global path\n",
    "    X2 = Conv2D(160,(13,13),strides=(1,1),padding='valid')(X_input)\n",
    "    X2 = BatchNormalization()(X2)\n",
    "    X21 = Conv2D(160,(13,13),strides=(1,1),padding='valid')(X_input)\n",
    "    X21 = BatchNormalization()(X21)\n",
    "    # Max-out\n",
    "    X2 = layers.Maximum()([X2,X21])\n",
    "  \n",
    "    # Local path Conv2\n",
    "    X3 = Conv2D(64,(3,3),strides=(1,1),padding='valid')(X)\n",
    "    X3 = BatchNormalization()(X3)\n",
    "    X31 =  Conv2D(64,(3,3),strides=(1,1),padding='valid')(X)\n",
    "    X31 = BatchNormalization()(X31)\n",
    "    X = layers.Maximum()([X3,X31])\n",
    "    X = Conv2D(64,(2,2),strides=(1,1),padding='valid',activation='relu')(X)\n",
    "  \n",
    "    # Merging the two paths\n",
    "    X = Concatenate()([X2,X])\n",
    "    #X = Conv2D(5,(21,21),strides=(1,1))(X)\n",
    "    #X = Activation('softmax')(X)\n",
    "  \n",
    "    #model = Model(inputs = X_input, outputs = X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SaclX3B4I5e8"
   },
   "outputs": [],
   "source": [
    "def input_cascade(input_shape1,input_shape2):\n",
    "  \n",
    "    X1_input = Input(input_shape1)\n",
    "    # 1st two-path of cascade\n",
    "    X1 = two_path(X1_input)\n",
    "    X1 = Conv2D(5,(21,21),strides=(1,1),padding='valid',activation='relu')(X1)\n",
    "    X1 = BatchNormalization()(X1)\n",
    "  \n",
    "    X2_input = Input(input_shape2)\n",
    "    #Concatenating the output of 1st to input of 2nd\n",
    "    X2_input1 = Concatenate()([X1,X2_input])\n",
    "    #X2_input1 = Input(tensor = X2_input1)\n",
    "    X2 = two_path(X2_input1)\n",
    "    # Fully convolutional softmax classification\n",
    "    X2 = Conv2D(5,(21,21),strides=(1,1),padding='valid')(X2)\n",
    "    X2 = BatchNormalization()(X2)\n",
    "    X2 = Activation('softmax')(X2)\n",
    "    X2 = layers.Reshape((5,))(X2)\n",
    "    model = Model(inputs=[X1_input,X2_input],outputs=X2)\n",
    "    return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gl0YpjrhI6QU"
   },
   "outputs": [],
   "source": [
    "def MFCcascade(input_shape1,input_shape2):\n",
    "  \n",
    "    # 1st two-path\n",
    "    X1_input = Input(input_shape1)\n",
    "    X1 = two_path(X1_input)\n",
    "    X1 = Conv2D(5,(21,21),strides=(1,1),padding='valid',activation='relu')(X1)\n",
    "    X1 = BatchNormalization()(X1)\n",
    "    #X1 = MaxPooling2D((2,2))(X1)\n",
    "  \n",
    "    #2nd two-path \n",
    "    X2_input = Input(input_shape2)\n",
    "    X2 = two_path(X2_input)\n",
    "  \n",
    "    # Concatenate before classification\n",
    "    X2 = Concatenate()([X1,X2])\n",
    "    X2 = Conv2D(5,(21,21),strides=(1,1),padding='valid',activation='relu')(X2)\n",
    "    X2 = BatchNormalization()(X2)\n",
    "    X2 = Activation('softmax')(X2)\n",
    "    X2 = layers.Reshape((5,))(X2) #Added \n",
    "  \n",
    "    model = Model(inputs=[X1_input,X2_input],outputs=X2)\n",
    "    return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vhQlYq3Ojdvu"
   },
   "outputs": [],
   "source": [
    "def two_pathcnn(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Conv2D(64,(7,7),strides=(1,1),padding='valid')(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X1 = Conv2D(64,(7,7),strides=(1,1),padding='valid')(X_input)\n",
    "    X1 = BatchNormalization()(X1)\n",
    "    X = layers.Maximum()([X,X1])\n",
    "    X = Conv2D(64,(4,4),strides=(1,1),padding='valid',activation='relu')(X)\n",
    "  \n",
    "    X2 = Conv2D(160,(13,13),strides=(1,1),padding='valid')(X_input)\n",
    "    X2 = BatchNormalization()(X2)\n",
    "    X21 = Conv2D(160,(13,13),strides=(1,1),padding='valid')(X_input)\n",
    "    X21 = BatchNormalization()(X21)\n",
    "    X2 = layers.Maximum()([X2,X21])\n",
    "  \n",
    "    X3 = Conv2D(64,(3,3),strides=(1,1),padding='valid')(X)\n",
    "    X3 = BatchNormalization()(X3)\n",
    "    X31 =  Conv2D(64,(3,3),strides=(1,1),padding='valid')(X)\n",
    "    X31 = BatchNormalization()(X31)\n",
    "    X = layers.Maximum()([X3,X31])\n",
    "    X = Conv2D(64,(2,2),strides=(1,1),padding='valid',activation='relu')(X)\n",
    "  \n",
    "    X = Concatenate()([X2,X])\n",
    "    X = Conv2D(5,(21,21),strides=(1,1),padding='valid')(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    X = layers.Reshape((5,))(X)\n",
    "  \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1wniC4jjhbe",
    "outputId": "fc6e540e-d568-41db-e9ad-e29dcbfb494a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 33, 33, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 27, 27, 64)   12608       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 27, 27, 64)   12608       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 27, 27, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 27, 27, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " maximum (Maximum)              (None, 27, 27, 64)   0           ['batch_normalization[0][0]',    \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 24, 24, 64)   65600       ['maximum[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 22, 22, 64)   36928       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 22, 22, 64)   36928       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 21, 21, 160)  108320      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 21, 21, 160)  108320      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 22, 22, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 22, 22, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 21, 21, 160)  640        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 21, 21, 160)  640        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " maximum_2 (Maximum)            (None, 22, 22, 64)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " maximum_1 (Maximum)            (None, 21, 21, 160)  0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 21, 21, 64)   16448       ['maximum_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 21, 21, 224)  0           ['maximum_1[0][0]',              \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 1, 1, 5)      493925      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1, 1, 5)      0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 5)            0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 893,989\n",
      "Trainable params: 892,837\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m0 = two_pathcnn((33,33,1))\n",
    "m0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1fVPzaOI8lL",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "98b456fa-2350-4780-ccde-79846234ac0e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 53, 53, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 47, 47, 64)   12608       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 47, 47, 64)   12608       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 47, 47, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 47, 47, 64)  256         ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 33, 33, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " maximum_3 (Maximum)            (None, 47, 47, 64)   0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 27, 27, 64)   12608       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 27, 27, 64)   12608       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 44, 44, 64)   65600       ['maximum_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 27, 27, 64)  256         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 27, 27, 64)  256         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 42, 42, 64)   36928       ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 42, 42, 64)   36928       ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " maximum_6 (Maximum)            (None, 27, 27, 64)   0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 41, 41, 160)  108320      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 41, 41, 160)  108320      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 42, 42, 64)  256         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 42, 42, 64)  256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 24, 24, 64)   65600       ['maximum_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 41, 41, 160)  640        ['conv2d_12[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 41, 41, 160)  640        ['conv2d_13[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " maximum_5 (Maximum)            (None, 42, 42, 64)   0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 22, 22, 64)   36928       ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 22, 22, 64)   36928       ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " maximum_4 (Maximum)            (None, 41, 41, 160)  0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 41, 41, 64)   16448       ['maximum_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 21, 21, 160)  108320      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 21, 21, 160)  108320      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 22, 22, 64)  256         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 22, 22, 64)  256         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 41, 41, 224)  0           ['maximum_4[0][0]',              \n",
      "                                                                  'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 21, 21, 160)  640        ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 21, 21, 160)  640        ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " maximum_8 (Maximum)            (None, 22, 22, 64)   0           ['batch_normalization_17[0][0]', \n",
      "                                                                  'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 21, 21, 5)    493925      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " maximum_7 (Maximum)            (None, 21, 21, 160)  0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 21, 21, 64)   16448       ['maximum_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 21, 21, 5)   20          ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 21, 21, 224)  0           ['maximum_7[0][0]',              \n",
      "                                                                  'conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 21, 21, 229)  0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 1, 1, 5)      504950      ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 1, 1, 5)     20          ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1, 1, 5)      0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 5)            0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,799,043\n",
      "Trainable params: 1,796,719\n",
      "Non-trainable params: 2,324\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m3 = MFCcascade((53,53,1),(33,33,1))\n",
    "m3.summary()\n",
    "# m3.save('trial_MFCcascade_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLgC18wqJAFi",
    "outputId": "461cb1a4-ca6a-4714-eedf-ec88e62f0ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 65, 65, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 59, 59, 64)   3200        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 59, 59, 64)   3200        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 59, 59, 64)  256         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 59, 59, 64)  256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " maximum_9 (Maximum)            (None, 59, 59, 64)   0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 56, 56, 64)   65600       ['maximum_9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 54, 54, 64)   36928       ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 54, 54, 64)   36928       ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 53, 53, 160)  27200       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 53, 53, 160)  27200       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 54, 54, 64)  256         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 54, 54, 64)  256         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 53, 53, 160)  640        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 53, 53, 160)  640        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " maximum_11 (Maximum)           (None, 54, 54, 64)   0           ['batch_normalization_24[0][0]', \n",
      "                                                                  'batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " maximum_10 (Maximum)           (None, 53, 53, 160)  0           ['batch_normalization_22[0][0]', \n",
      "                                                                  'batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 53, 53, 64)   16448       ['maximum_11[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 53, 53, 224)  0           ['maximum_10[0][0]',             \n",
      "                                                                  'conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 33, 33, 5)    493925      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 33, 33, 5)   20          ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 33, 33, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 33, 33, 6)    0           ['batch_normalization_26[0][0]', \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 27, 27, 64)   18880       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 27, 27, 64)   18880       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 27, 27, 64)  256         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 27, 27, 64)  256         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " maximum_12 (Maximum)           (None, 27, 27, 64)   0           ['batch_normalization_27[0][0]', \n",
      "                                                                  'batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 24, 24, 64)   65600       ['maximum_12[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 22, 22, 64)   36928       ['conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 22, 22, 64)   36928       ['conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 21, 21, 160)  162400      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 21, 21, 160)  162400      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 22, 22, 64)  256         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 22, 22, 64)  256         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 21, 21, 160)  640        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 21, 21, 160)  640        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " maximum_14 (Maximum)           (None, 22, 22, 64)   0           ['batch_normalization_31[0][0]', \n",
      "                                                                  'batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " maximum_13 (Maximum)           (None, 21, 21, 160)  0           ['batch_normalization_29[0][0]', \n",
      "                                                                  'batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 21, 21, 64)   16448       ['maximum_14[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 21, 21, 224)  0           ['maximum_13[0][0]',             \n",
      "                                                                  'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 1, 1, 5)      493925      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 1, 1, 5)     20          ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 1, 1, 5)      0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 5)            0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,727,666\n",
      "Trainable params: 1,725,342\n",
      "Non-trainable params: 2,324\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1 = input_cascade((65,65,1),(33,33,1))\n",
    "m1.summary()\n",
    "# m1.save('trial_0001_input_cascasde_acc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UW2ETYf1JIT4"
   },
   "source": [
    "Training the architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VMOzNLPrJE8n"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = keras.sum(keras.round(keras.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = keras.sum(keras.round(keras.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + keras.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_yLabel_y5class(y_Label): #Converts the 4 segment output to 5, since the 5th label is supposed to indicate no label\n",
    "    arr = list(y_Label)\n",
    "    if np.sum(y_Label) == 0:\n",
    "        arr.append(1)\n",
    "    else:\n",
    "        arr.append(0)\n",
    "    return np.asarray(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since sklearn 's compute_class_weights wasn't working, we found and used this file from here:\n",
    "# https://gist.github.com/angeligareta/83d9024c5e72ac9ebc34c9f0b073c64c\n",
    "def generate_class_weights(class_series, multi_class=True, one_hot_encoded=False):\n",
    "  \"\"\"\n",
    "  Method to generate class weights given a set of multi-class or multi-label labels, both one-hot-encoded or not.\n",
    "\n",
    "  Some examples of different formats of class_series and their outputs are:\n",
    "    - generate_class_weights(['mango', 'lemon', 'banana', 'mango'], multi_class=True, one_hot_encoded=False)\n",
    "    {'banana': 1.3333333333333333, 'lemon': 1.3333333333333333, 'mango': 0.6666666666666666}\n",
    "    - generate_class_weights([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]], multi_class=True, one_hot_encoded=True)\n",
    "    {0: 0.6666666666666666, 1: 1.3333333333333333, 2: 1.3333333333333333}\n",
    "    - generate_class_weights([['mango', 'lemon'], ['mango'], ['lemon', 'banana'], ['lemon']], multi_class=False, one_hot_encoded=False)\n",
    "    {'banana': 1.3333333333333333, 'lemon': 0.4444444444444444, 'mango': 0.6666666666666666}\n",
    "    - generate_class_weights([[0, 1, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0]], multi_class=False, one_hot_encoded=True)\n",
    "    {0: 1.3333333333333333, 1: 0.4444444444444444, 2: 0.6666666666666666}\n",
    "\n",
    "  The output is a dictionary in the format { class_label: class_weight }. In case the input is one hot encoded, the class_label would be index\n",
    "  of appareance of the label when the dataset was processed. \n",
    "  In multi_class this is np.unique(class_series) and in multi-label np.unique(np.concatenate(class_series)).\n",
    "\n",
    "  Author: Angel Igareta (angel@igareta.com)\n",
    "  \"\"\"\n",
    "  if multi_class:\n",
    "    # If class is one hot encoded, transform to categorical labels to use compute_class_weight   \n",
    "    if one_hot_encoded:\n",
    "        class_series = np.argmax(class_series, axis=1)\n",
    "  \n",
    "    # Compute class weights with sklearn method\n",
    "    class_labels = np.unique(class_series)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=class_series)\n",
    "    return dict(zip(class_labels, class_weights))\n",
    "  else:\n",
    "    # It is neccessary that the multi-label values are one-hot encoded\n",
    "    mlb = None\n",
    "    if not one_hot_encoded:\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        class_series = mlb.fit_transform(class_series)\n",
    "\n",
    "    n_samples = len(class_series)\n",
    "    n_classes = len(class_series[0])\n",
    "\n",
    "    # Count each class frequency\n",
    "    class_count = [0] * n_classes\n",
    "    for classes in class_series:\n",
    "        for index in range(n_classes):\n",
    "            if classes[index] != 0:\n",
    "                class_count[index] += 1\n",
    "    \n",
    "    # Compute class weights using balanced method\n",
    "    class_weights = [n_samples / (n_classes * freq) if freq > 0 else 1 for freq in class_count]\n",
    "    class_labels = range(len(class_weights)) if mlb is None else mlb.classes_\n",
    "    return dict(zip(class_labels, class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcHSBKCdiAqW"
   },
   "source": [
    "Training for the InputCascadeCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCh_e-WQJWAX",
    "outputId": "18d43a08-c8ab-4595-fdb1-e1290ee6705c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 240, 240, 4)\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (4744,)\n",
      "d[2] shape (4744, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 8.704587155963303, 1: 7.53015873015873, 2: 1, 3: 10.093617021276597, 4: 2.8838905775075987}\n",
      "{0: 0.34954317712938404, 1: 12.55026455026455, 2: 16.822695035460992}\n",
      "(4744, 5)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zooha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 3], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 596s 1s/step - loss: 1.5343 - accuracy: 0.1220\n",
      "Epoch 2/2\n",
      "593/593 [==============================] - 596s 1s/step - loss: 1.3345 - accuracy: 0.1109\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (4779,)\n",
      "d[2] shape (4779, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 8.932710280373831, 1: 7.834426229508197, 2: 1, 3: 10.061052631578947, 4: 2.95}\n",
      "{0: 0.34918895221394125, 1: 13.057377049180328, 2: 16.768421052631577}\n",
      "(4779, 5)\n",
      "Epoch 1/2\n",
      "598/598 [==============================] - 598s 998ms/step - loss: 1.3606 - accuracy: 0.0456\n",
      "Epoch 2/2\n",
      "598/598 [==============================] - 602s 1s/step - loss: 1.2829 - accuracy: 0.0506\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5273,)\n",
      "d[2] shape (5273, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 24.525581395348837, 1: 13.1825, 2: 1, 3: 10.872164948453609, 4: 4.793636363636364}\n",
      "{0: 0.34491104133961276, 1: 21.970833333333335, 2: 18.120274914089347}\n",
      "(5273, 5)\n",
      "Epoch 1/2\n",
      "660/660 [==============================] - 659s 998ms/step - loss: 1.2960 - accuracy: 0.0311\n",
      "Epoch 2/2\n",
      "660/660 [==============================] - 659s 999ms/step - loss: 1.2085 - accuracy: 0.0609\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5267,)\n",
      "d[2] shape (5267, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 12.248837209302325, 1: 4.745045045045045, 2: 1, 3: 2.3725225225225226, 4: 1.4007978723404255}\n",
      "{0: 0.3815837136854307, 1: 7.908408408408408, 2: 3.954204204204204}\n",
      "(5267, 5)\n",
      "Epoch 1/2\n",
      "659/659 [==============================] - 659s 998ms/step - loss: 1.2514 - accuracy: 0.0678\n",
      "Epoch 2/2\n",
      "659/659 [==============================] - 661s 1s/step - loss: 1.1729 - accuracy: 0.0737\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5323,)\n",
      "d[2] shape (5323, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 14.583561643835617, 1: 4.399173553719009, 2: 1, 3: 2.2747863247863247, 4: 1.3596424010217114}\n",
      "{0: 0.38463761832502347, 1: 7.3319559228650135, 2: 3.7913105413105415}\n",
      "(5323, 5)\n",
      "Epoch 1/2\n",
      "666/666 [==============================] - 666s 999ms/step - loss: 1.1618 - accuracy: 0.0949\n",
      "Epoch 2/2\n",
      "666/666 [==============================] - 667s 1s/step - loss: 1.1312 - accuracy: 0.0879\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5341,)\n",
      "d[2] shape (5341, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 14.83611111111111, 1: 4.307258064516129, 2: 1, 3: 2.1889344262295083, 4: 1.322029702970297}\n",
      "{0: 0.3866087585957293, 1: 7.178763440860215, 2: 3.648224043715847}\n",
      "(5341, 5)\n",
      "Epoch 1/2\n",
      "668/668 [==============================] - 669s 1s/step - loss: 1.1510 - accuracy: 0.0874\n",
      "Epoch 2/2\n",
      "668/668 [==============================] - 668s 1s/step - loss: 1.0943 - accuracy: 0.0805\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5411,)\n",
      "d[2] shape (5411, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 13.360493827160493, 1: 4.381376518218623, 2: 1, 3: 2.1261296660117877, 4: 1.2929510155316606}\n",
      "{0: 0.387468671679198, 1: 7.302294197031039, 2: 3.5435494433529797}\n",
      "(5411, 5)\n",
      "Epoch 1/2\n",
      "677/677 [==============================] - 678s 999ms/step - loss: 1.0752 - accuracy: 0.1040\n",
      "Epoch 2/2\n",
      "677/677 [==============================] - 676s 999ms/step - loss: 1.0755 - accuracy: 0.1026\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5432,)\n",
      "d[2] shape (5432, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 12.206741573033709, 1: 4.162452107279694, 2: 1, 3: 2.121875, 4: 1.2603248259860789}\n",
      "{0: 0.38863847749874797, 1: 6.937420178799489, 2: 3.5364583333333335}\n",
      "(5432, 5)\n",
      "Epoch 1/2\n",
      "679/679 [==============================] - 675s 993ms/step - loss: 1.0762 - accuracy: 0.0963\n",
      "Epoch 2/2\n",
      "679/679 [==============================] - 675s 994ms/step - loss: 1.0741 - accuracy: 0.0937\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5488,)\n",
      "d[2] shape (5488, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 11.2, 1: 4.157575757575757, 2: 1, 3: 2.1952, 4: 1.2733178654292343}\n",
      "{0: 0.38724244990121365, 1: 6.929292929292929, 2: 3.6586666666666665}\n",
      "(5488, 5)\n",
      "Epoch 1/2\n",
      "686/686 [==============================] - 687s 1000ms/step - loss: 1.0979 - accuracy: 0.0913\n",
      "Epoch 2/2\n",
      "686/686 [==============================] - 685s 999ms/step - loss: 1.0766 - accuracy: 0.0911\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5514,)\n",
      "d[2] shape (5514, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 10.025454545454545, 1: 4.0101818181818185, 2: 1, 3: 2.2644763860369608, 4: 1.2646788990825688}\n",
      "{0: 0.3867845117845118, 1: 6.683636363636364, 2: 3.7741273100616017}\n",
      "(5514, 5)\n",
      "Epoch 1/2\n",
      "690/690 [==============================] - 686s 993ms/step - loss: 1.0691 - accuracy: 0.0941\n",
      "Epoch 2/2\n",
      "690/690 [==============================] - 689s 999ms/step - loss: 1.0608 - accuracy: 0.1014\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5567,)\n",
      "d[2] shape (5567, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 7.137179487179488, 1: 4.019494584837545, 2: 1, 3: 2.49082774049217, 4: 1.2652272727272726}\n",
      "{0: 0.3831647050726134, 1: 6.699157641395908, 2: 4.15137956748695}\n",
      "(5567, 5)\n",
      "Epoch 1/2\n",
      "696/696 [==============================] - 696s 999ms/step - loss: 1.0648 - accuracy: 0.0975\n",
      "Epoch 2/2\n",
      "696/696 [==============================] - 694s 997ms/step - loss: 1.0296 - accuracy: 0.1053\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5597,)\n",
      "d[2] shape (5597, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 6.396571428571429, 1: 4.1003663003663, 2: 1, 3: 2.65260663507109, 4: 1.2866666666666666}\n",
      "{0: 0.38059295525635795, 1: 6.833943833943834, 2: 4.421011058451817}\n",
      "(5597, 5)\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 694s 991ms/step - loss: 1.0314 - accuracy: 0.1138\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 695s 993ms/step - loss: 1.0089 - accuracy: 0.1029\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5653,)\n",
      "d[2] shape (5653, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 6.6505882352941175, 1: 3.967017543859649, 2: 1, 3: 2.6665094339622644, 4: 1.2862343572241184}\n",
      "{0: 0.3811353829557713, 1: 6.6116959064327485, 2: 4.444182389937107}\n",
      "(5653, 5)\n",
      "Epoch 1/2\n",
      "707/707 [==============================] - 701s 989ms/step - loss: 1.0181 - accuracy: 0.1033\n",
      "Epoch 2/2\n",
      "707/707 [==============================] - 699s 989ms/step - loss: 1.0142 - accuracy: 0.0962\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5682,)\n",
      "d[2] shape (5682, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 5.888082901554404, 1: 3.9458333333333333, 2: 1, 3: 2.8268656716417913, 4: 1.2869762174405437}\n",
      "{0: 0.37940705128205127, 1: 6.576388888888889, 2: 4.711442786069652}\n",
      "(5682, 5)\n",
      "Epoch 1/2\n",
      "711/711 [==============================] - 706s 992ms/step - loss: 1.0270 - accuracy: 0.1035\n",
      "Epoch 2/2\n",
      "711/711 [==============================] - 704s 990ms/step - loss: 1.0084 - accuracy: 0.1144\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5729,)\n",
      "d[2] shape (5729, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 6.030526315789474, 1: 3.8066445182724253, 2: 1, 3: 2.9304347826086956, 4: 1.299092970521542}\n",
      "{0: 0.3791277877043214, 1: 6.344407530454042, 2: 4.884057971014493}\n",
      "(5729, 5)\n",
      "Epoch 1/2\n",
      "717/717 [==============================] - 711s 990ms/step - loss: 1.0226 - accuracy: 0.1087\n",
      "Epoch 2/2\n",
      "717/717 [==============================] - 712s 994ms/step - loss: 1.0108 - accuracy: 0.1094\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5758,)\n",
      "d[2] shape (5758, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 6.292896174863388, 1: 3.7633986928104575, 2: 1, 3: 2.9154430379746836, 4: 1.3027149321266969}\n",
      "{0: 0.37953991167358775, 1: 6.272331154684096, 2: 4.859071729957806}\n",
      "(5758, 5)\n",
      "Epoch 1/2\n",
      "720/720 [==============================] - 716s 992ms/step - loss: 1.0220 - accuracy: 0.1004\n",
      "Epoch 2/2\n",
      "720/720 [==============================] - 713s 991ms/step - loss: 0.9937 - accuracy: 0.1056\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5808,)\n",
      "d[2] shape (5808, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 6.525842696629214, 1: 3.699363057324841, 2: 1, 3: 2.9861182519280205, 4: 1.3185017026106698}\n",
      "{0: 0.3792360430950049, 1: 6.165605095541402, 2: 4.976863753213368}\n",
      "(5808, 5)\n",
      "Epoch 1/2\n",
      "726/726 [==============================] - 726s 999ms/step - loss: 1.0230 - accuracy: 0.0950\n",
      "Epoch 2/2\n",
      "726/726 [==============================] - 722s 995ms/step - loss: 0.9960 - accuracy: 0.0999\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5828,)\n",
      "d[2] shape (5828, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 7.021686746987951, 1: 3.8091503267973854, 2: 1, 3: 2.9360201511335013, 4: 1.3413118527042578}\n",
      "{0: 0.3790569105691057, 1: 6.348583877995643, 2: 4.893366918555835}\n",
      "(5828, 5)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729/729 [==============================] - 726s 995ms/step - loss: 1.0061 - accuracy: 0.0954\n",
      "Epoch 2/2\n",
      "729/729 [==============================] - 724s 993ms/step - loss: 1.0049 - accuracy: 0.0966\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5869,)\n",
      "d[2] shape (5869, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 8.505797101449275, 1: 3.691194968553459, 2: 1, 3: 2.949246231155779, 4: 1.374473067915691}\n",
      "{0: 0.3796493951743321, 1: 6.151991614255765, 2: 4.915410385259632}\n",
      "(5869, 5)\n",
      "Epoch 1/2\n",
      "734/734 [==============================] - 730s 993ms/step - loss: 1.0023 - accuracy: 0.0901\n",
      "Epoch 2/2\n",
      "734/734 [==============================] - 732s 998ms/step - loss: 0.9729 - accuracy: 0.1036\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5895,)\n",
      "d[2] shape (5895, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 11.228571428571428, 1: 3.5194029850746267, 2: 1, 3: 2.977272727272727, 4: 1.4102870813397128}\n",
      "{0: 0.3805189775367932, 1: 5.865671641791045, 2: 4.962121212121212}\n",
      "(5895, 5)\n",
      "Epoch 1/2\n",
      "737/737 [==============================] - 732s 992ms/step - loss: 1.0076 - accuracy: 0.0948\n",
      "Epoch 2/2\n",
      "737/737 [==============================] - 734s 996ms/step - loss: 0.9849 - accuracy: 0.0950\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5922,)\n",
      "d[2] shape (5922, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 12.735483870967743, 1: 3.413256484149856, 2: 1, 3: 3.0447300771208226, 4: 1.4287092882991557}\n",
      "{0: 0.38064018511376785, 1: 5.688760806916426, 2: 5.074550128534704}\n",
      "(5922, 5)\n",
      "Epoch 1/2\n",
      "741/741 [==============================] - 739s 996ms/step - loss: 1.0192 - accuracy: 0.0826\n",
      "Epoch 2/2\n",
      "741/741 [==============================] - 738s 996ms/step - loss: 0.9901 - accuracy: 0.0868\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5937,)\n",
      "d[2] shape (5937, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 13.493181818181819, 1: 3.2983333333333333, 2: 1, 3: 3.157978723404255, 4: 1.4410194174757283}\n",
      "{0: 0.38050374927898484, 1: 5.497222222222222, 2: 5.263297872340425}\n",
      "(5937, 5)\n",
      "Epoch 1/2\n",
      "743/743 [==============================] - 737s 991ms/step - loss: 1.0375 - accuracy: 0.1068\n",
      "Epoch 2/2\n",
      "743/743 [==============================] - 740s 997ms/step - loss: 1.0090 - accuracy: 0.0911\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5957,)\n",
      "d[2] shape (5957, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 14.708641975308643, 1: 3.194101876675603, 2: 1, 3: 3.273076923076923, 4: 1.456479217603912}\n",
      "{0: 0.38039591315453386, 1: 5.323503127792672, 2: 5.455128205128205}\n",
      "(5957, 5)\n",
      "Epoch 1/2\n",
      "745/745 [==============================] - 745s 998ms/step - loss: 1.0208 - accuracy: 0.0839\n",
      "Epoch 2/2\n",
      "745/745 [==============================] - 741s 995ms/step - loss: 0.9999 - accuracy: 0.0915\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5327,)\n",
      "d[2] shape (5327, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 20.48846153846154, 1: 14.205333333333334, 2: 1, 3: 14.205333333333334, 4: 5.274257425742574}\n",
      "{0: 0.34299143648187497, 1: 23.675555555555555, 2: 23.675555555555555}\n",
      "(5327, 5)\n",
      "Epoch 1/2\n",
      "666/666 [==============================] - 656s 984ms/step - loss: 1.2356 - accuracy: 0.0505\n",
      "Epoch 2/2\n",
      "666/666 [==============================] - 658s 988ms/step - loss: 1.1384 - accuracy: 0.0529\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5229,)\n",
      "d[2] shape (5229, 5)\n",
      "NP.unique yints [0]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 1, 1: 1, 2: 1, 3: 1, 4: 1}\n",
      "{0: 1.0}\n",
      "(5229, 5)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zooha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654/654 [==============================] - 647s 987ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 2/2\n",
      "654/654 [==============================] - 645s 986ms/step - loss: 0.0000e+00 - accuracy: 0.0258\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5261,)\n",
      "d[2] shape (5261, 5)\n",
      "NP.unique yints [0]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 1, 1: 1, 2: 1, 3: 1, 4: 1}\n",
      "{0: 1.0}\n",
      "(5261, 5)\n",
      "Epoch 1/2\n",
      "658/658 [==============================] - 655s 994ms/step - loss: 0.0000e+00 - accuracy: 0.0283\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - 654s 994ms/step - loss: 0.0000e+00 - accuracy: 0.0293\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5307,)\n",
      "d[2] shape (5307, 5)\n",
      "NP.unique yints [0]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 1, 1: 1, 2: 1, 3: 1, 4: 1}\n",
      "{0: 1.0}\n",
      "(5307, 5)\n",
      "Epoch 1/2\n",
      "664/664 [==============================] - 665s 1000ms/step - loss: 0.0000e+00 - accuracy: 0.0256\n",
      "Epoch 2/2\n",
      "664/664 [==============================] - 665s 1s/step - loss: 0.0000e+00 - accuracy: 0.0307\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5380,)\n",
      "d[2] shape (5380, 5)\n",
      "NP.unique yints [0 1]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 1, 1: 538.0, 2: 1, 3: 1, 4: 538.0}\n",
      "{0: 0.5001859427296392, 1: 1345.0}\n",
      "(5380, 5)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zooha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - 678s 1s/step - loss: 0.3481 - accuracy: 0.0292\n",
      "Epoch 2/2\n",
      "673/673 [==============================] - 673s 1s/step - loss: 0.2919 - accuracy: 0.0212\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5423,)\n",
      "d[2] shape (5423, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 1, 1: 542.3, 2: 1, 3: 542.3, 4: 271.15}\n",
      "{0: 0.33357938118964137, 1: 903.8333333333334, 2: 903.8333333333334}\n",
      "(5423, 5)\n",
      "Epoch 1/2\n",
      "678/678 [==============================] - 681s 1s/step - loss: 0.9834 - accuracy: 0.0227\n",
      "Epoch 2/2\n",
      "678/678 [==============================] - 680s 1s/step - loss: 0.6957 - accuracy: 0.0343\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5475,)\n",
      "d[2] shape (5475, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 1095.0, 1: 219.0, 2: 1, 3: 57.63157894736842, 4: 43.8}\n",
      "{0: 0.33480095395340304, 1: 365.0, 2: 96.05263157894737}\n",
      "(5475, 5)\n",
      "Epoch 1/2\n",
      "685/685 [==============================] - 688s 1s/step - loss: 2.0953 - accuracy: 0.0336\n",
      "Epoch 2/2\n",
      "685/685 [==============================] - 690s 1s/step - loss: 1.4470 - accuracy: 0.0206\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5515,)\n",
      "d[2] shape (5515, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 551.5, 1: 137.875, 2: 1, 3: 26.902439024390244, 4: 21.627450980392158}\n",
      "{0: 0.336321502622271, 1: 229.79166666666666, 2: 44.83739837398374}\n",
      "(5515, 5)\n",
      "Epoch 1/2\n",
      "690/690 [==============================] - 695s 1s/step - loss: 1.3012 - accuracy: 0.0279\n",
      "Epoch 2/2\n",
      "690/690 [==============================] - 692s 1s/step - loss: 0.9938 - accuracy: 0.0321\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5568,)\n",
      "d[2] shape (5568, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 222.72, 1: 92.8, 2: 1, 3: 12.237362637362637, 4: 10.311111111111112}\n",
      "{0: 0.339615736505032, 1: 154.66666666666666, 2: 20.395604395604394}\n",
      "(5568, 5)\n",
      "Epoch 1/2\n",
      "696/696 [==============================] - 714s 1s/step - loss: 1.4007 - accuracy: 0.0280\n",
      "Epoch 2/2\n",
      "696/696 [==============================] - 701s 1s/step - loss: 1.0787 - accuracy: 0.0413\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5599,)\n",
      "d[2] shape (5599, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 69.9875, 1: 53.32380952380952, 2: 1, 3: 9.178688524590164, 4: 7.042767295597485}\n",
      "{0: 0.34206989247311825, 1: 88.87301587301587, 2: 15.297814207650273}\n",
      "(5599, 5)\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 713s 1s/step - loss: 1.2052 - accuracy: 0.0627\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 704s 1s/step - loss: 1.0852 - accuracy: 0.0732\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5630,)\n",
      "d[2] shape (5630, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 34.121212121212125, 1: 46.916666666666664, 2: 1, 3: 8.661538461538461, 4: 6.021390374331551}\n",
      "{0: 0.34270757243730215, 1: 78.19444444444444, 2: 14.435897435897436}\n",
      "(5630, 5)\n",
      "Epoch 1/2\n",
      "704/704 [==============================] - 713s 1s/step - loss: 1.1432 - accuracy: 0.0538\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 711s 1s/step - loss: 1.0754 - accuracy: 0.0455\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5664,)\n",
      "d[2] shape (5664, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 19.873684210526317, 1: 39.06206896551724, 2: 1, 3: 8.99047619047619, 4: 5.343396226415094}\n",
      "{0: 0.34271192593937194, 1: 65.10344827586206, 2: 14.984126984126984}\n",
      "(5664, 5)\n",
      "Epoch 1/2\n",
      "708/708 [==============================] - 709s 1000ms/step - loss: 1.0881 - accuracy: 0.0590\n",
      "Epoch 2/2\n",
      "708/708 [==============================] - 719s 1s/step - loss: 1.0270 - accuracy: 0.0456\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5691,)\n",
      "d[2] shape (5691, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 16.738235294117647, 1: 30.762162162162163, 2: 1, 3: 8.96220472440945, 4: 4.906034482758621}\n",
      "{0: 0.3432241722453411, 1: 51.270270270270274, 2: 14.937007874015748}\n",
      "(5691, 5)\n",
      "Epoch 1/2\n",
      "712/712 [==============================] - 710s 995ms/step - loss: 1.0597 - accuracy: 0.0311\n",
      "Epoch 2/2\n",
      "712/712 [==============================] - 709s 996ms/step - loss: 0.9977 - accuracy: 0.0392\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5707,)\n",
      "d[2] shape (5707, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 15.852777777777778, 1: 25.364444444444445, 2: 1, 3: 7.712162162162162, 4: 4.307169811320755}\n",
      "{0: 0.34500060452182324, 1: 42.27407407407407, 2: 12.853603603603604}\n",
      "(5707, 5)\n",
      "Epoch 1/2\n",
      "714/714 [==============================] - 722s 1s/step - loss: 1.0399 - accuracy: 0.0380\n",
      "Epoch 2/2\n",
      "714/714 [==============================] - 705s 987ms/step - loss: 0.9980 - accuracy: 0.0445\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5726,)\n",
      "d[2] shape (5726, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 12.313978494623656, 1: 23.37142857142857, 2: 1, 3: 7.9527777777777775, 4: 4.004195804195804}\n",
      "{0: 0.3449605397915537, 1: 38.95238095238095, 2: 13.25462962962963}\n",
      "(5726, 5)\n",
      "Epoch 1/2\n",
      "716/716 [==============================] - 701s 978ms/step - loss: 1.0084 - accuracy: 0.0426\n",
      "Epoch 2/2\n",
      "716/716 [==============================] - 698s 975ms/step - loss: 0.9544 - accuracy: 0.0479\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5736,)\n",
      "d[2] shape (5736, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 10.721495327102804, 1: 21.645283018867925, 2: 1, 3: 7.911724137931034, 4: 3.761311475409836}\n",
      "{0: 0.3452509931383171, 1: 36.075471698113205, 2: 13.186206896551724}\n",
      "(5736, 5)\n",
      "Epoch 1/2\n",
      "717/717 [==============================] - 703s 979ms/step - loss: 0.9971 - accuracy: 0.0471\n",
      "Epoch 2/2\n",
      "717/717 [==============================] - 709s 989ms/step - loss: 0.9795 - accuracy: 0.0460\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5748,)\n",
      "d[2] shape (5748, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 8.57910447761194, 1: 15.966666666666667, 2: 1, 3: 8.57910447761194, 4: 3.3811764705882354}\n",
      "{0: 0.3457235654998196, 1: 26.61111111111111, 2: 14.298507462686567}\n",
      "(5748, 5)\n",
      "Epoch 1/2\n",
      "719/719 [==============================] - 712s 989ms/step - loss: 1.0595 - accuracy: 0.0421\n",
      "Epoch 2/2\n",
      "719/719 [==============================] - 711s 988ms/step - loss: 1.0020 - accuracy: 0.0423\n",
      "(240, 240, 1)\n",
      "Returned\n",
      "Y_ints shape (5753,)\n",
      "d[2] shape (5753, 5)\n",
      "NP.unique yints [0 1 3]\n",
      "d[2][0] [0 0 0 0 0]\n",
      "Temp FIx {0: 7.423225806451613, 1: 12.372043010752687, 2: 1, 3: 9.2048, 4: 3.0847184986595173}\n",
      "{0: 0.3464619090635351, 1: 20.620071684587813, 2: 15.341333333333333}\n",
      "(5753, 5)\n",
      "Epoch 1/2\n",
      " 99/720 [===>..........................] - ETA: 10:14 - loss: 1.0142 - accuracy: 0.0429"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20620/431000898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m#             with tf.device('/GPU:0'):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, specificity, f1_m])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtemp_fix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#,class_weight= d_class_weights))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Note that the output here will look different since the random prints have been removed\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    fold1 = os.listdir(os.path.join(data_path, 'Training', 'Brains')) \n",
    "    fold2 = os.listdir(os.path.join(data_path, 'Training', 'Labels'))\n",
    "    fold1.sort(key=str.lower) \n",
    "    fold2.sort(key=str.lower)\n",
    "\n",
    "    arr = []\n",
    "    Y_labels = []\n",
    "\n",
    "    for B_Lpath, S_Lpath in zip(fold1, fold2):\n",
    "        B_path = os.path.join(data_path, 'Training','Brains',B_Lpath)\n",
    "        S_path = os.path.join(data_path, 'Training','Labels', S_Lpath)\n",
    "        if \"raw\" not in B_path:\n",
    "            brain_img = sitk.ReadImage(B_path)\n",
    "            plt.show(brain_img)\n",
    "            arr.append(sitk.GetArrayFromImage(brain_img))\n",
    "            label_img = sitk.ReadImage(S_path)\n",
    "            Y_label_array = sitk.GetArrayFromImage(label_img)\n",
    "            Y_label = convert_y_2D_y_3D(Y_label_array)\n",
    "            Y_labels.append(Y_label)\n",
    "    arr = np.asarray(arr)\n",
    "    Y_labels = np.asarray(Y_labels)\n",
    "    data = arr\n",
    "    data = data[..., np.newaxis]\n",
    "    info = []\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        d = data_gen(data,Y_labels,i,1) # Change this last parameter based on which model is being trained:\n",
    "                                        # 0 : twopathCNN\n",
    "                                        # 1 : InputCascadeCNN\n",
    "                                        # 2 : LocalCascadeCNN (Model Not Implemented by Code's Developer)\n",
    "                                        # 3 : MFCCascadeCNN\n",
    "                                        #\n",
    "        if(len(d) != 0):\n",
    "            y = np.zeros((d[2].shape[0],5))\n",
    "            for j in range(y.shape[0]):\n",
    "\n",
    "                y[j] = d[2][j]\n",
    "            X1 = d[0]\n",
    "            X2 = d[1]\n",
    "            y_ints = np.argmax(d[2], axis=1)\n",
    "            print(\"Y_ints shape\",y_ints.shape)\n",
    "            print(\"d[2] shape\", d[2].shape)\n",
    "            print(\"NP.unique yints\",  np.unique(y_ints))\n",
    "            print(\"d[2][0]\",d[2][0])\n",
    "            class_weights = generate_class_weights(d[2], multi_class=False, one_hot_encoded=True)\n",
    "            print(\"Class weights for this patch: \", class_weights)\n",
    "            print(y.shape)\n",
    "#             with tf.device('/GPU:0'): #If the GPU could have handled the sheer amount of data, of even batch size 1, \n",
    "                                        #this would be uncommented\n",
    "\n",
    "\n",
    "            #Here, change m1 to the name of the model being trained\n",
    "            m1.compile(optimizer = 'adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])#, specificity, f1_m])\n",
    "            info.append(m1.fit([X1,X2],y,epochs=2,batch_size=8,class_weight= class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_img = sitk.ReadImage(os.path.join(data_path, \"Training/Labels/seg_0.mhd\"))\n",
    "Y_label_array = sitk.GetArrayFromImage(label_img)\n",
    "Y_label = convert_y_2D_y_3D(Y_label_array)\n",
    "plt.imshow(Y_label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvl-uvjA67nS"
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bPg1k-1o6_xQ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21184/3521611758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfold1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Testing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Brains'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfold2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Testing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Labels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfold1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfold2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "fold1 = os.listdir(os.path.join(data_path, 'Testing', 'Brains')) \n",
    "fold2 = os.listdir(os.path.join(data_path, 'Testing', 'Labels'))\n",
    "fold1.sort(key=str.lower) \n",
    "fold2.sort(key=str.lower)\n",
    "\n",
    "arr = []\n",
    "Y_labels = []\n",
    "\n",
    "for B_Lpath, S_Lpath in zip(fold1, fold2):\n",
    "    B_path = os.path.join(data_path, 'Testing','Brains',B_Lpath)\n",
    "    S_path = os.path.join(data_path, 'Testing','Labels', S_Lpath)\n",
    "    if \"raw\" not in B_path:\n",
    "        brain_img = sitk.ReadImage(B_path)\n",
    "        plt.show(brain_img)\n",
    "        arr.append(sitk.GetArrayFromImage(brain_img))\n",
    "        label_img = sitk.ReadImage(S_path)\n",
    "        Y_label_array = sitk.GetArrayFromImage(label_img)\n",
    "        Y_label = convert_y_2D_y_3D(Y_label_array)\n",
    "        Y_labels.append(Y_label)\n",
    "arr = np.asarray(arr)\n",
    "Y_labels = np.asarray(Y_labels)\n",
    "data = arr\n",
    "data = data[..., np.newaxis]\n",
    "info = []\n",
    "\n",
    "d = data_gen(data,Y_labels,22,1) #The 3rd argument is the Image we want to predict based on its patches\n",
    "if(len(d) != 0):\n",
    "    y = np.zeros((d[2].shape[0],5))\n",
    "    for j in range(y.shape[0]):\n",
    "        y[j] = d[2][j]\n",
    "    X1 = d[0]\n",
    "    X2 = d[1]\n",
    "    pred = m1.predict([X1,X2],batch_size = 256) \n",
    "    pred = np.around(pred)\n",
    "    #print(pred.shape)\n",
    "    pred1 = np.argmax(pred.reshape(y.shape[0],5)[:,1:4],axis = 1)\n",
    "    y2 = np.argmax(y.reshape(y.shape[0],5)[:,0:5],axis = 1)\n",
    "    f1 = metrics.f1_score(y2,pred1,average='micro')\n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mo2zV30v69EP"
   },
   "outputs": [],
   "source": [
    "pred = model.predict([X1,X2],batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6L0zsHc7Jt1d"
   },
   "outputs": [],
   "source": [
    "pred = np.around(pred)\n",
    "print(pred.shape)\n",
    "pred1 = np.argmax(pred.reshape(y.shape[0],5)[:,1:4],axis = 1)\n",
    "y2 = np.argmax(y.reshape(y.shape[0],5)[:,1:4],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLNqgyHt7u3A"
   },
   "outputs": [],
   "source": [
    "f1 = metrics.f1_score(y2,pred1,average='micro')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hd08lzus-5u4"
   },
   "outputs": [],
   "source": [
    "pred2 = m1.predict([X1,X2],batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tg44hHMbdntD"
   },
   "outputs": [],
   "source": [
    "pred2 = np.around(pred2)\n",
    "pred3 = np.argmax(pred2.reshape(y.shape[0],5)[:,1:4],axis = 1)\n",
    "y2 = np.argmax(y.reshape(y.shape[0],5)[:,1:4],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKrjYzv1_Nef"
   },
   "outputs": [],
   "source": [
    "f1 = metrics.f1_score(y2,pred3,average='micro')\n",
    "f1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinalCode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
